{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project Abusive Word Twitter Datasets Indonesia CNN Method.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHXkYCI0ludT"
      },
      "source": [
        "Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3XOqlVnQGS_"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Embedding, Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50D8gTIilxCw"
      },
      "source": [
        "Read CSV File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dYAXPjadlI3i",
        "outputId": "0440a3ca-a2ac-4dce-be47-bd306d4932e6"
      },
      "source": [
        "df = pd.read_csv('tweet.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abusive</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>cowok usaha lacak perhati gue lantas remeh per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>telat tau edan sarap gue gaul cigax jifla cal ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>41 kadang pikir percaya tuhan jatuh kali kali ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>ku tau mata sipit lihat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>kaum cebong kafir lihat dongok dungu haha</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Abusive                                              Tweet\n",
              "0        1  cowok usaha lacak perhati gue lantas remeh per...\n",
              "1        1  telat tau edan sarap gue gaul cigax jifla cal ...\n",
              "2        0  41 kadang pikir percaya tuhan jatuh kali kali ...\n",
              "3        0                            ku tau mata sipit lihat\n",
              "4        1          kaum cebong kafir lihat dongok dungu haha"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuwC3k6mly3r"
      },
      "source": [
        "Drop Missing Rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amCq7-1UlNTX"
      },
      "source": [
        "# drop missing rows\n",
        "df.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bD1Pp85l0i_"
      },
      "source": [
        "Print Lenght of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm12Datjlfri",
        "outputId": "4b9bb2a9-d71d-47d2-85ae-a29067249e96"
      },
      "source": [
        "text = df[\"Tweet\"].tolist()\n",
        "print(len(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcnanCkLuF6c"
      },
      "source": [
        "Make it to Categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucRFc5iJuFH1",
        "outputId": "3e823fc2-c7cd-4a61-858f-4a1769ba8b6d"
      },
      "source": [
        "y = df[\"Abusive\"]\n",
        "y = to_categorical(y)\n",
        "print(y)\n",
        "#0 itu negatif, 1 itu positif"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6AfkUo4mHE0"
      },
      "source": [
        "Count Data Each Categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVrhJbf_mEtE",
        "outputId": "5f4a964c-89d0-4d6c-af7f-7b8b0b0fdec3"
      },
      "source": [
        "df[\"Abusive\"].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    8088\n",
              "1    5033\n",
              "Name: Abusive, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH0x1jptm7nh"
      },
      "source": [
        "Do Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXRKRirwm-li"
      },
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od7zmpVOnBD1"
      },
      "source": [
        "# if you want to print tokenizer word, run code below \n",
        "# token.index_word "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NegjhvTnL9Q"
      },
      "source": [
        "Print Lenght of Index of Word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjZAT2innQOl",
        "outputId": "1e89f08a-7f23-4fb8-bae2-aeddbef11601"
      },
      "source": [
        "vocab = len(token.index_word)+1\n",
        "print(vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSYPIUiPn1YD"
      },
      "source": [
        "Test Text to Tokenize Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRB_WEIWnULT",
        "outputId": "48fbd0c9-9281-45cf-8136-102646354a3c"
      },
      "source": [
        "x = ['sinting kau ya']\n",
        "token.texts_to_sequences(x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[558, 1035, 8]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEmrQUYln9Mv"
      },
      "source": [
        "Encode Every Each Tweet Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm3AM6wLoBt_"
      },
      "source": [
        "encode_text = token.texts_to_sequences(text)\n",
        "# if you want to print every tokenizer tweet\n",
        "# print(encode_text)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkoEI0mEoOzf"
      },
      "source": [
        "Do Padding Every Encode Tweet Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFaDbqgfoVn8",
        "outputId": "49267e17-349f-40b9-d3e2-214df9addf6d"
      },
      "source": [
        "max_kata = 100\n",
        "x=pad_sequences(encode_text,maxlen = max_kata, padding=\"post\")\n",
        "print(x)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 324  161 3546 ...    0    0    0]\n",
            " [1908   49  464 ...    0    0    0]\n",
            " [3547  598  101 ...    0    0    0]\n",
            " ...\n",
            " [  66   66  376 ...    0    0    0]\n",
            " [ 111 2819  291 ...    0    0    0]\n",
            " [ 569  325    8 ...    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-SCJ53wNN2V"
      },
      "source": [
        "# **80 20 ratio**\n",
        "Performing learning for 80% data training and 20% data testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCz4v-Rbthge"
      },
      "source": [
        "Split data test and test test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezm4E--wtlw-"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1, test_size = 0.2, stratify=y)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFct96Y7tnCl"
      },
      "source": [
        "Change to Data to Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaQDZkMqtq7Z"
      },
      "source": [
        "x_train = np.asarray(x_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_SSH7z2t20F"
      },
      "source": [
        "Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo1q2gRxt4hD",
        "outputId": "85ec0f4e-370a-4007-93d3-314d2a6e4aae"
      },
      "source": [
        "vec_size = 100\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(vocab,vec_size,input_length=max_kata))\n",
        "model.add(Conv1D(64,3,activation='relu'))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          1326800   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 98, 64)            19264     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,346,194\n",
            "Trainable params: 1,346,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g733dI0ivLWK"
      },
      "source": [
        "from keras.metrics import Precision, Recall\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy', Precision(), Recall()])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kd8SXbDvMov",
        "outputId": "0b4969ac-48eb-4938-b81b-c05771ad25c6"
      },
      "source": [
        "model.fit(x_train,y_train, epochs=10, validation_data =(x_test,y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "263/263 [==============================] - 9s 32ms/step - loss: 0.4495 - accuracy: 0.7806 - precision: 0.7806 - recall: 0.7806 - val_loss: 0.2209 - val_accuracy: 0.9120 - val_precision: 0.9120 - val_recall: 0.9120\n",
            "Epoch 2/10\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.1824 - accuracy: 0.9364 - precision: 0.9364 - recall: 0.9364 - val_loss: 0.1942 - val_accuracy: 0.9192 - val_precision: 0.9192 - val_recall: 0.9192\n",
            "Epoch 3/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.1112 - accuracy: 0.9616 - precision: 0.9616 - recall: 0.9616 - val_loss: 0.2198 - val_accuracy: 0.9158 - val_precision: 0.9158 - val_recall: 0.9158\n",
            "Epoch 4/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0784 - accuracy: 0.9762 - precision: 0.9762 - recall: 0.9762 - val_loss: 0.2531 - val_accuracy: 0.9116 - val_precision: 0.9116 - val_recall: 0.9116\n",
            "Epoch 5/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0529 - accuracy: 0.9849 - precision: 0.9849 - recall: 0.9849 - val_loss: 0.2830 - val_accuracy: 0.9147 - val_precision: 0.9147 - val_recall: 0.9147\n",
            "Epoch 6/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0396 - accuracy: 0.9887 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.3176 - val_accuracy: 0.9063 - val_precision: 0.9063 - val_recall: 0.9063\n",
            "Epoch 7/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0338 - accuracy: 0.9904 - precision: 0.9904 - recall: 0.9904 - val_loss: 0.3419 - val_accuracy: 0.9063 - val_precision: 0.9063 - val_recall: 0.9063\n",
            "Epoch 8/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0268 - accuracy: 0.9919 - precision: 0.9919 - recall: 0.9919 - val_loss: 0.3710 - val_accuracy: 0.9059 - val_precision: 0.9059 - val_recall: 0.9059\n",
            "Epoch 9/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0213 - accuracy: 0.9939 - precision: 0.9939 - recall: 0.9939 - val_loss: 0.3814 - val_accuracy: 0.9040 - val_precision: 0.9040 - val_recall: 0.9040\n",
            "Epoch 10/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0199 - accuracy: 0.9934 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.4102 - val_accuracy: 0.9029 - val_precision: 0.9029 - val_recall: 0.9029\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb856d0acd0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g81gHnxjvRGa"
      },
      "source": [
        "Evaluate and print Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diiCq6bembt4"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    ''' Function to calculate f1 score '''\n",
        "    \n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL1-nLk9dHcE",
        "outputId": "479be743-4a82-4524-ee38-c373be39c04f"
      },
      "source": [
        "# Evaluate model on the test set\n",
        "loss, accuracy, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
        "# Print metrics\n",
        "print('')\n",
        "print('Accuracy  : {:.4f}'.format(accuracy))\n",
        "print('Precision : {:.4f}'.format(precision))\n",
        "print('Recall    : {:.4f}'.format(recall))\n",
        "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy  : 0.9029\n",
            "Precision : 0.9029\n",
            "Recall    : 0.9029\n",
            "F1 Score  : 0.9029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDCHxeXIzjgl"
      },
      "source": [
        "Get Encode of Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_uQQnmUzmiT"
      },
      "source": [
        "def get_encode(x):\n",
        "  x = token.texts_to_sequences(x)\n",
        "  x = pad_sequences(x,maxlen = max_kata, padding = \"post\")\n",
        "  return x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDVmlhWCzqMm"
      },
      "source": [
        "Get Sentiment Classesof Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caFA2Sz3zulF"
      },
      "source": [
        "def get_sentiment_classes(x):\n",
        "  x = get_encode(x)\n",
        "  predict_x=model.predict(x) \n",
        "  classes_x=np.argmax(predict_x,axis=1)\n",
        "  sentiment_classes = ['tidak kasar','kasar']\n",
        "  print('kata tersebut mengandung konotasi',sentiment_classes[classes_x[0]])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKEGdVfezveT"
      },
      "source": [
        "Predict Data 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvFAB00Qzy0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d6aee2-5585-4d67-b1bc-b699f2721fc5"
      },
      "source": [
        "# untuk melakukan prediksi kata yang tidak kasar \n",
        "get_sentiment_classes(['ibu peri hari ini cantik banget ya'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi tidak kasar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PbAQ7q4zz9v"
      },
      "source": [
        "Predict Data 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVCaPYuFz1fq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfcb9b31-d0b0-4e30-f310-513d3ec84770"
      },
      "source": [
        "# untuk melakukan prediksi kata yang kasar\n",
        "get_sentiment_classes(['bangsat cok raimu koyok asu'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi kasar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC-cd_2RNVTt"
      },
      "source": [
        "# **70 30 ratio**\n",
        "Performing learning for 70% data training and 30% data testing. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYXIyDBoN0-9"
      },
      "source": [
        "Split data test and test test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w7OAVK1N0--"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1, test_size = 0.2, stratify=y)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HGV7x5ZN0--"
      },
      "source": [
        "Change to Data to Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5KfaP0MN0--"
      },
      "source": [
        "x_train = np.asarray(x_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO8i8fr4N0--"
      },
      "source": [
        "Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDV1S_lrN0--",
        "outputId": "f9fff039-a3e9-419c-9e32-da93b7c31537"
      },
      "source": [
        "vec_size = 100\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(vocab,vec_size,input_length=max_kata))\n",
        "model.add(Conv1D(64,3,activation='relu'))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 100)          1326800   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 98, 64)            19264     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,346,194\n",
            "Trainable params: 1,346,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsY4HNNpN0--"
      },
      "source": [
        "from keras.metrics import Precision, Recall\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy', Precision(), Recall()])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eRCvkUBN0-_",
        "outputId": "98ac5863-1182-4dff-8e3f-4de9a7c1e35e"
      },
      "source": [
        "model.fit(x_train,y_train, epochs=10, validation_data =(x_test,y_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "263/263 [==============================] - 9s 32ms/step - loss: 0.4480 - accuracy: 0.7805 - precision_1: 0.7805 - recall_1: 0.7805 - val_loss: 0.2047 - val_accuracy: 0.9227 - val_precision_1: 0.9227 - val_recall_1: 0.9227\n",
            "Epoch 2/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.1851 - accuracy: 0.9341 - precision_1: 0.9341 - recall_1: 0.9341 - val_loss: 0.1911 - val_accuracy: 0.9265 - val_precision_1: 0.9265 - val_recall_1: 0.9265\n",
            "Epoch 3/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.1164 - accuracy: 0.9613 - precision_1: 0.9613 - recall_1: 0.9613 - val_loss: 0.2067 - val_accuracy: 0.9196 - val_precision_1: 0.9196 - val_recall_1: 0.9196\n",
            "Epoch 4/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0781 - accuracy: 0.9762 - precision_1: 0.9762 - recall_1: 0.9762 - val_loss: 0.2375 - val_accuracy: 0.9147 - val_precision_1: 0.9147 - val_recall_1: 0.9147\n",
            "Epoch 5/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0520 - accuracy: 0.9831 - precision_1: 0.9831 - recall_1: 0.9831 - val_loss: 0.2778 - val_accuracy: 0.9120 - val_precision_1: 0.9120 - val_recall_1: 0.9120\n",
            "Epoch 6/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0400 - accuracy: 0.9887 - precision_1: 0.9887 - recall_1: 0.9887 - val_loss: 0.3089 - val_accuracy: 0.9078 - val_precision_1: 0.9078 - val_recall_1: 0.9078\n",
            "Epoch 7/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0315 - accuracy: 0.9907 - precision_1: 0.9907 - recall_1: 0.9907 - val_loss: 0.3124 - val_accuracy: 0.9082 - val_precision_1: 0.9082 - val_recall_1: 0.9082\n",
            "Epoch 8/10\n",
            "263/263 [==============================] - 9s 34ms/step - loss: 0.0239 - accuracy: 0.9938 - precision_1: 0.9938 - recall_1: 0.9938 - val_loss: 0.3406 - val_accuracy: 0.9093 - val_precision_1: 0.9093 - val_recall_1: 0.9093\n",
            "Epoch 9/10\n",
            "263/263 [==============================] - 9s 35ms/step - loss: 0.0225 - accuracy: 0.9933 - precision_1: 0.9933 - recall_1: 0.9933 - val_loss: 0.3671 - val_accuracy: 0.9063 - val_precision_1: 0.9063 - val_recall_1: 0.9063\n",
            "Epoch 10/10\n",
            "263/263 [==============================] - 8s 32ms/step - loss: 0.0205 - accuracy: 0.9938 - precision_1: 0.9938 - recall_1: 0.9938 - val_loss: 0.3880 - val_accuracy: 0.9040 - val_precision_1: 0.9040 - val_recall_1: 0.9040\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb854125a90>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFKemL1-N0-_"
      },
      "source": [
        "Evaluate and print Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bn8itdlN0-_"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    ''' Function to calculate f1 score '''\n",
        "    \n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voFsUDB5N0-_",
        "outputId": "9d099108-da4b-461b-cc36-a9f7ca64b1a8"
      },
      "source": [
        "# Evaluate model on the test set\n",
        "loss, accuracy, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
        "# Print metrics\n",
        "print('')\n",
        "print('Accuracy  : {:.4f}'.format(accuracy))\n",
        "print('Precision : {:.4f}'.format(precision))\n",
        "print('Recall    : {:.4f}'.format(recall))\n",
        "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy  : 0.9040\n",
            "Precision : 0.9040\n",
            "Recall    : 0.9040\n",
            "F1 Score  : 0.9040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl7DDjqWN0-_"
      },
      "source": [
        "Get Encode of Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JckxuL8eN0-_"
      },
      "source": [
        "def get_encode(x):\n",
        "  x = token.texts_to_sequences(x)\n",
        "  x = pad_sequences(x,maxlen = max_kata, padding = \"post\")\n",
        "  return x"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26saoZ8PN0-_"
      },
      "source": [
        "Get Sentiment Classesof Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlHpbGVBN0_A"
      },
      "source": [
        "def get_sentiment_classes(x):\n",
        "  x = get_encode(x)\n",
        "  predict_x=model.predict(x) \n",
        "  classes_x=np.argmax(predict_x,axis=1)\n",
        "  sentiment_classes = ['tidak kasar','kasar']\n",
        "  print('kata tersebut mengandung konotasi',sentiment_classes[classes_x[0]])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhUq1or9N0_A"
      },
      "source": [
        "Predict Data 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ijoqxHN0_B",
        "outputId": "46752e75-be85-4ce2-ec6c-0acd5f3c8b0b"
      },
      "source": [
        "# untuk melakukan prediksi kata yang tidak kasar \n",
        "get_sentiment_classes(['ibu peri hari ini cantik banget ya'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi tidak kasar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2FoND1KN0_B"
      },
      "source": [
        "Predict Data 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbSfoQmFN0_B",
        "outputId": "3ce8a423-7f09-4ecd-934e-9a679eb21153"
      },
      "source": [
        "# untuk melakukan prediksi kata yang kasar\n",
        "get_sentiment_classes(['bangsat cok raimu koyok asu'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi kasar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WNkqlXoNt73"
      },
      "source": [
        "# **60 40 ratio**\n",
        "Performing learning for 60% data training and 40% data testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h6rs63aN1wk"
      },
      "source": [
        "Split data test and test test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL7X2xg2N1wl"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1, test_size = 0.4, stratify=y)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.4, random_state=1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd3_tt5GN1wl"
      },
      "source": [
        "Change to Data to Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3oC2n1sN1wm"
      },
      "source": [
        "x_train = np.asarray(x_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIPnlWQrN1wm"
      },
      "source": [
        "Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo5n0zglN1wm",
        "outputId": "18b9402b-3f4b-443b-ad60-0f9f50914093"
      },
      "source": [
        "vec_size = 100\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(vocab,vec_size,input_length=max_kata))\n",
        "model.add(Conv1D(64,3,activation='relu'))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 100)          1326800   \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 98, 64)            19264     \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,346,194\n",
            "Trainable params: 1,346,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpqWpplaN1wm"
      },
      "source": [
        "from keras.metrics import Precision, Recall\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy', Precision(), Recall()])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_etqRW0YN1wn",
        "outputId": "463924d1-0254-42e5-bd25-0cdf24272cb8"
      },
      "source": [
        "model.fit(x_train,y_train, epochs=10, validation_data =(x_test,y_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "148/148 [==============================] - 6s 37ms/step - loss: 0.5624 - accuracy: 0.7065 - precision_2: 0.7065 - recall_2: 0.7065 - val_loss: 0.3836 - val_accuracy: 0.8512 - val_precision_2: 0.8512 - val_recall_2: 0.8512\n",
            "Epoch 2/10\n",
            "148/148 [==============================] - 5s 35ms/step - loss: 0.2348 - accuracy: 0.9164 - precision_2: 0.9164 - recall_2: 0.9164 - val_loss: 0.2387 - val_accuracy: 0.9126 - val_precision_2: 0.9126 - val_recall_2: 0.9126\n",
            "Epoch 3/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.1192 - accuracy: 0.9638 - precision_2: 0.9638 - recall_2: 0.9638 - val_loss: 0.2446 - val_accuracy: 0.9120 - val_precision_2: 0.9120 - val_recall_2: 0.9120\n",
            "Epoch 4/10\n",
            "148/148 [==============================] - 5s 35ms/step - loss: 0.0680 - accuracy: 0.9803 - precision_2: 0.9803 - recall_2: 0.9803 - val_loss: 0.2723 - val_accuracy: 0.9087 - val_precision_2: 0.9087 - val_recall_2: 0.9087\n",
            "Epoch 5/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.0439 - accuracy: 0.9877 - precision_2: 0.9877 - recall_2: 0.9877 - val_loss: 0.2971 - val_accuracy: 0.9080 - val_precision_2: 0.9080 - val_recall_2: 0.9080\n",
            "Epoch 6/10\n",
            "148/148 [==============================] - 5s 35ms/step - loss: 0.0323 - accuracy: 0.9928 - precision_2: 0.9928 - recall_2: 0.9928 - val_loss: 0.3266 - val_accuracy: 0.9030 - val_precision_2: 0.9030 - val_recall_2: 0.9030\n",
            "Epoch 7/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.0237 - accuracy: 0.9953 - precision_2: 0.9953 - recall_2: 0.9953 - val_loss: 0.3490 - val_accuracy: 0.9030 - val_precision_2: 0.9030 - val_recall_2: 0.9030\n",
            "Epoch 8/10\n",
            "148/148 [==============================] - 6s 38ms/step - loss: 0.0171 - accuracy: 0.9943 - precision_2: 0.9943 - recall_2: 0.9943 - val_loss: 0.3842 - val_accuracy: 0.9011 - val_precision_2: 0.9011 - val_recall_2: 0.9011\n",
            "Epoch 9/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.0142 - accuracy: 0.9958 - precision_2: 0.9958 - recall_2: 0.9958 - val_loss: 0.3957 - val_accuracy: 0.8994 - val_precision_2: 0.8994 - val_recall_2: 0.8994\n",
            "Epoch 10/10\n",
            "148/148 [==============================] - 5s 35ms/step - loss: 0.0106 - accuracy: 0.9970 - precision_2: 0.9970 - recall_2: 0.9970 - val_loss: 0.4161 - val_accuracy: 0.8985 - val_precision_2: 0.8985 - val_recall_2: 0.8985\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb853457550>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BtC46R4N1wn"
      },
      "source": [
        "Evaluate and print Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTxhu7lvN1wn"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    ''' Function to calculate f1 score '''\n",
        "    \n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NqD45eGN1wn",
        "outputId": "2b3cf83c-7e12-4584-ce8a-4139fe2c2964"
      },
      "source": [
        "# Evaluate model on the test set\n",
        "loss, accuracy, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
        "# Print metrics\n",
        "print('')\n",
        "print('Accuracy  : {:.4f}'.format(accuracy))\n",
        "print('Precision : {:.4f}'.format(precision))\n",
        "print('Recall    : {:.4f}'.format(recall))\n",
        "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy  : 0.8985\n",
            "Precision : 0.8985\n",
            "Recall    : 0.8985\n",
            "F1 Score  : 0.8985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY9aQqdbN1wn"
      },
      "source": [
        "Get Encode of Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og9fHX93N1wn"
      },
      "source": [
        "def get_encode(x):\n",
        "  x = token.texts_to_sequences(x)\n",
        "  x = pad_sequences(x,maxlen = max_kata, padding = \"post\")\n",
        "  return x"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9vP0ZZ5N1wn"
      },
      "source": [
        "Get Sentiment Classesof Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Acu-j3UN1wo"
      },
      "source": [
        "def get_sentiment_classes(x):\n",
        "  x = get_encode(x)\n",
        "  predict_x=model.predict(x) \n",
        "  classes_x=np.argmax(predict_x,axis=1)\n",
        "  sentiment_classes = ['tidak kasar','kasar']\n",
        "  print('kata tersebut mengandung konotasi',sentiment_classes[classes_x[0]])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeEXAC0-N1wo"
      },
      "source": [
        "Predict Data 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB3eV_00N1wo",
        "outputId": "cc684555-2864-4e5b-c687-d80dccacc325"
      },
      "source": [
        "# untuk melakukan prediksi kata yang tidak kasar \n",
        "get_sentiment_classes(['ibu peri hari ini cantik banget ya'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi kasar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6uwMPtQN1wo"
      },
      "source": [
        "Predict Data 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v84OY99eN1wo",
        "outputId": "6f444fdc-e730-469a-96b6-6d60bd4a0343"
      },
      "source": [
        "# untuk melakukan prediksi kata yang kasar\n",
        "get_sentiment_classes(['bangsat cok raimu koyok asu'])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi kasar\n"
          ]
        }
      ]
    }
  ]
}