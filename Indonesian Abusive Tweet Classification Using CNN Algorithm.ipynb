{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Indonesian Abusive Tweet Classification Using CNN Algorithm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHXkYCI0ludT"
      },
      "source": [
        "Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3XOqlVnQGS_"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Embedding, Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50D8gTIilxCw"
      },
      "source": [
        "Read CSV File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dYAXPjadlI3i",
        "outputId": "c77dac6e-73e3-47b1-bf99-f4b5012291c6"
      },
      "source": [
        "df = pd.read_csv('tweet.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abusive</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>cowok usaha lacak perhati gue lantas remeh per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>telat tau edan sarap gue gaul cigax jifla cal ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>41 kadang pikir percaya tuhan jatuh kali kali ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>ku tau mata sipit lihat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>kaum cebong kafir lihat dongok dungu haha</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Abusive                                              Tweet\n",
              "0        1  cowok usaha lacak perhati gue lantas remeh per...\n",
              "1        1  telat tau edan sarap gue gaul cigax jifla cal ...\n",
              "2        0  41 kadang pikir percaya tuhan jatuh kali kali ...\n",
              "3        0                            ku tau mata sipit lihat\n",
              "4        1          kaum cebong kafir lihat dongok dungu haha"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuwC3k6mly3r"
      },
      "source": [
        "Drop Missing Rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amCq7-1UlNTX"
      },
      "source": [
        "# drop missing rows\n",
        "df.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bD1Pp85l0i_"
      },
      "source": [
        "Print Lenght of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm12Datjlfri",
        "outputId": "31c0c748-f68b-4d49-d9d2-fa9056cbdae6"
      },
      "source": [
        "text = df[\"Tweet\"].tolist()\n",
        "print(len(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcnanCkLuF6c"
      },
      "source": [
        "Make it to Categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucRFc5iJuFH1",
        "outputId": "9d417345-45fc-429d-d942-de304279172e"
      },
      "source": [
        "y = df[\"Abusive\"]\n",
        "y = to_categorical(y)\n",
        "print(y)\n",
        "#0 itu negatif, 1 itu positif"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6AfkUo4mHE0"
      },
      "source": [
        "Count Data Each Categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVrhJbf_mEtE",
        "outputId": "179bc92a-37bd-46fe-dc4d-a32794efe622"
      },
      "source": [
        "df[\"Abusive\"].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    8088\n",
              "1    5033\n",
              "Name: Abusive, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH0x1jptm7nh"
      },
      "source": [
        "Do Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXRKRirwm-li"
      },
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od7zmpVOnBD1"
      },
      "source": [
        "# if you want to print tokenizer word, run code below \n",
        "# token.index_word "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NegjhvTnL9Q"
      },
      "source": [
        "Print Lenght of Index of Word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjZAT2innQOl",
        "outputId": "d774c02b-0795-42bb-a611-95cb33b22a6a"
      },
      "source": [
        "vocab = len(token.index_word)+1\n",
        "print(vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSYPIUiPn1YD"
      },
      "source": [
        "Test Text to Tokenize Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRB_WEIWnULT",
        "outputId": "6cae93cd-f317-44e0-da70-943148dc0d44"
      },
      "source": [
        "x = ['sinting kau ya']\n",
        "token.texts_to_sequences(x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[558, 1035, 8]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEmrQUYln9Mv"
      },
      "source": [
        "Encode Every Each Tweet Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm3AM6wLoBt_"
      },
      "source": [
        "encode_text = token.texts_to_sequences(text)\n",
        "# if you want to print every tokenizer tweet\n",
        "# print(encode_text)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkoEI0mEoOzf"
      },
      "source": [
        "Do Padding Every Encode Tweet Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFaDbqgfoVn8",
        "outputId": "1175a10f-5168-4287-f38e-923236af846e"
      },
      "source": [
        "max_kata = 100\n",
        "x=pad_sequences(encode_text,maxlen = max_kata, padding=\"post\")\n",
        "print(x)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 324  161 3546 ...    0    0    0]\n",
            " [1908   49  464 ...    0    0    0]\n",
            " [3547  598  101 ...    0    0    0]\n",
            " ...\n",
            " [  66   66  376 ...    0    0    0]\n",
            " [ 111 2819  291 ...    0    0    0]\n",
            " [ 569  325    8 ...    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-SCJ53wNN2V"
      },
      "source": [
        "# **80 20 ratio**\n",
        "Performing learning for 80% data training and 20% data testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCz4v-Rbthge"
      },
      "source": [
        "Split data test and test test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezm4E--wtlw-"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1, test_size = 0.2, stratify=y)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFct96Y7tnCl"
      },
      "source": [
        "Change to Data to Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaQDZkMqtq7Z"
      },
      "source": [
        "x_train = np.asarray(x_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_SSH7z2t20F"
      },
      "source": [
        "Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo1q2gRxt4hD",
        "outputId": "4b6bccd7-bf4e-4cb5-b471-b6bfdfbe11a8"
      },
      "source": [
        "vec_size = 100\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(vocab,vec_size,input_length=max_kata))\n",
        "model.add(Conv1D(64,3,activation='relu'))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          1326800   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 98, 64)            19264     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,346,194\n",
            "Trainable params: 1,346,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g733dI0ivLWK"
      },
      "source": [
        "from keras.metrics import Precision, Recall\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy', Precision(), Recall()])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kd8SXbDvMov",
        "outputId": "ab6128f4-621a-4351-d43f-542ea934aa38"
      },
      "source": [
        "model.fit(x_train,y_train, epochs=10, validation_data =(x_test,y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "263/263 [==============================] - 9s 32ms/step - loss: 0.4459 - accuracy: 0.7833 - precision: 0.7833 - recall: 0.7833 - val_loss: 0.2179 - val_accuracy: 0.9166 - val_precision: 0.9166 - val_recall: 0.9166\n",
            "Epoch 2/10\n",
            "263/263 [==============================] - 9s 33ms/step - loss: 0.1781 - accuracy: 0.9390 - precision: 0.9390 - recall: 0.9390 - val_loss: 0.1945 - val_accuracy: 0.9253 - val_precision: 0.9253 - val_recall: 0.9253\n",
            "Epoch 3/10\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.1120 - accuracy: 0.9639 - precision: 0.9639 - recall: 0.9639 - val_loss: 0.2150 - val_accuracy: 0.9204 - val_precision: 0.9204 - val_recall: 0.9204\n",
            "Epoch 4/10\n",
            "263/263 [==============================] - 8s 32ms/step - loss: 0.0726 - accuracy: 0.9768 - precision: 0.9768 - recall: 0.9768 - val_loss: 0.2453 - val_accuracy: 0.9208 - val_precision: 0.9208 - val_recall: 0.9208\n",
            "Epoch 5/10\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.0516 - accuracy: 0.9857 - precision: 0.9857 - recall: 0.9857 - val_loss: 0.2762 - val_accuracy: 0.9173 - val_precision: 0.9173 - val_recall: 0.9173\n",
            "Epoch 6/10\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.0372 - accuracy: 0.9888 - precision: 0.9888 - recall: 0.9888 - val_loss: 0.3000 - val_accuracy: 0.9150 - val_precision: 0.9150 - val_recall: 0.9150\n",
            "Epoch 7/10\n",
            "263/263 [==============================] - 8s 32ms/step - loss: 0.0296 - accuracy: 0.9929 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.3397 - val_accuracy: 0.9090 - val_precision: 0.9090 - val_recall: 0.9090\n",
            "Epoch 8/10\n",
            "263/263 [==============================] - 9s 34ms/step - loss: 0.0242 - accuracy: 0.9942 - precision: 0.9942 - recall: 0.9942 - val_loss: 0.3551 - val_accuracy: 0.9078 - val_precision: 0.9078 - val_recall: 0.9078\n",
            "Epoch 9/10\n",
            "263/263 [==============================] - 8s 30ms/step - loss: 0.0182 - accuracy: 0.9951 - precision: 0.9951 - recall: 0.9951 - val_loss: 0.3853 - val_accuracy: 0.9051 - val_precision: 0.9051 - val_recall: 0.9051\n",
            "Epoch 10/10\n",
            "263/263 [==============================] - 8s 31ms/step - loss: 0.0162 - accuracy: 0.9951 - precision: 0.9951 - recall: 0.9951 - val_loss: 0.3980 - val_accuracy: 0.9044 - val_precision: 0.9044 - val_recall: 0.9044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2e88334d10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g81gHnxjvRGa"
      },
      "source": [
        "Evaluate and print Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diiCq6bembt4"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    ''' Function to calculate f1 score '''\n",
        "    \n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL1-nLk9dHcE",
        "outputId": "77f65c6c-a636-4916-f673-92dd80bf8bb6"
      },
      "source": [
        "# Evaluate model on the test set\n",
        "loss, accuracy, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
        "# Print metrics\n",
        "print('')\n",
        "print('Accuracy  : {:.4f}'.format(accuracy))\n",
        "print('Precision : {:.4f}'.format(precision))\n",
        "print('Recall    : {:.4f}'.format(recall))\n",
        "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy  : 0.9044\n",
            "Precision : 0.9044\n",
            "Recall    : 0.9044\n",
            "F1 Score  : 0.9044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDCHxeXIzjgl"
      },
      "source": [
        "Get Encode of Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_uQQnmUzmiT"
      },
      "source": [
        "def get_encode(x):\n",
        "  x = token.texts_to_sequences(x)\n",
        "  x = pad_sequences(x,maxlen = max_kata, padding = \"post\")\n",
        "  return x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDVmlhWCzqMm"
      },
      "source": [
        "Get Sentiment Classesof Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caFA2Sz3zulF"
      },
      "source": [
        "def get_sentiment_classes(x):\n",
        "  x = get_encode(x)\n",
        "  predict_x=model.predict(x) \n",
        "  classes_x=np.argmax(predict_x,axis=1)\n",
        "  sentiment_classes = ['tidak kasar','kasar']\n",
        "  print('kata tersebut mengandung konotasi',sentiment_classes[classes_x[0]])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKEGdVfezveT"
      },
      "source": [
        "Predict Data 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvFAB00Qzy0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e192df-4d27-4281-8320-a974a26f06ca"
      },
      "source": [
        "# untuk melakukan prediksi kata yang tidak kasar \n",
        "get_sentiment_classes(['ibu peri hari ini cantik banget ya'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi tidak kasar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PbAQ7q4zz9v"
      },
      "source": [
        "Predict Data 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVCaPYuFz1fq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3b603b-96ed-4e8a-a66c-e1be484a1581"
      },
      "source": [
        "# untuk melakukan prediksi kata yang kasar\n",
        "get_sentiment_classes(['bangsat cok raimu koyok asu'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi kasar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC-cd_2RNVTt"
      },
      "source": [
        "# **70 30 ratio**\n",
        "Performing learning for 70% data training and 30% data testing. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYXIyDBoN0-9"
      },
      "source": [
        "Split data test and test test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w7OAVK1N0--"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1, test_size = 0.3, stratify=y)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state=1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HGV7x5ZN0--"
      },
      "source": [
        "Change to Data to Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5KfaP0MN0--"
      },
      "source": [
        "x_train = np.asarray(x_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO8i8fr4N0--"
      },
      "source": [
        "Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDV1S_lrN0--",
        "outputId": "b6d2dfb4-3fa8-42d1-a4d9-2d259fe9de48"
      },
      "source": [
        "vec_size = 100\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(vocab,vec_size,input_length=max_kata))\n",
        "model.add(Conv1D(64,3,activation='relu'))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 100)          1326800   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 98, 64)            19264     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,346,194\n",
            "Trainable params: 1,346,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsY4HNNpN0--"
      },
      "source": [
        "from keras.metrics import Precision, Recall\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy', Precision(), Recall()])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eRCvkUBN0-_",
        "outputId": "26a02907-9483-4d8f-fb9a-b03139b0d32d"
      },
      "source": [
        "model.fit(x_train,y_train, epochs=10, validation_data =(x_test,y_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "201/201 [==============================] - 8s 35ms/step - loss: 0.4850 - accuracy: 0.7629 - precision_1: 0.7629 - recall_1: 0.7629 - val_loss: 0.2476 - val_accuracy: 0.9126 - val_precision_1: 0.9126 - val_recall_1: 0.9126\n",
            "Epoch 2/10\n",
            "201/201 [==============================] - 6s 32ms/step - loss: 0.1850 - accuracy: 0.9367 - precision_1: 0.9367 - recall_1: 0.9367 - val_loss: 0.2179 - val_accuracy: 0.9180 - val_precision_1: 0.9180 - val_recall_1: 0.9180\n",
            "Epoch 3/10\n",
            "201/201 [==============================] - 6s 32ms/step - loss: 0.1056 - accuracy: 0.9652 - precision_1: 0.9652 - recall_1: 0.9652 - val_loss: 0.2358 - val_accuracy: 0.9141 - val_precision_1: 0.9141 - val_recall_1: 0.9141\n",
            "Epoch 4/10\n",
            "201/201 [==============================] - 6s 32ms/step - loss: 0.0651 - accuracy: 0.9795 - precision_1: 0.9795 - recall_1: 0.9795 - val_loss: 0.2630 - val_accuracy: 0.9131 - val_precision_1: 0.9131 - val_recall_1: 0.9131\n",
            "Epoch 5/10\n",
            "201/201 [==============================] - 7s 33ms/step - loss: 0.0419 - accuracy: 0.9891 - precision_1: 0.9891 - recall_1: 0.9891 - val_loss: 0.2875 - val_accuracy: 0.9073 - val_precision_1: 0.9073 - val_recall_1: 0.9073\n",
            "Epoch 6/10\n",
            "201/201 [==============================] - 7s 37ms/step - loss: 0.0307 - accuracy: 0.9905 - precision_1: 0.9905 - recall_1: 0.9905 - val_loss: 0.3173 - val_accuracy: 0.9149 - val_precision_1: 0.9149 - val_recall_1: 0.9149\n",
            "Epoch 7/10\n",
            "201/201 [==============================] - 6s 31ms/step - loss: 0.0272 - accuracy: 0.9930 - precision_1: 0.9930 - recall_1: 0.9930 - val_loss: 0.3535 - val_accuracy: 0.9073 - val_precision_1: 0.9073 - val_recall_1: 0.9073\n",
            "Epoch 8/10\n",
            "201/201 [==============================] - 6s 32ms/step - loss: 0.0204 - accuracy: 0.9942 - precision_1: 0.9942 - recall_1: 0.9942 - val_loss: 0.3667 - val_accuracy: 0.9058 - val_precision_1: 0.9058 - val_recall_1: 0.9058\n",
            "Epoch 9/10\n",
            "201/201 [==============================] - 7s 33ms/step - loss: 0.0152 - accuracy: 0.9970 - precision_1: 0.9970 - recall_1: 0.9970 - val_loss: 0.3871 - val_accuracy: 0.9081 - val_precision_1: 0.9081 - val_recall_1: 0.9081\n",
            "Epoch 10/10\n",
            "201/201 [==============================] - 7s 37ms/step - loss: 0.0147 - accuracy: 0.9964 - precision_1: 0.9964 - recall_1: 0.9964 - val_loss: 0.4075 - val_accuracy: 0.9098 - val_precision_1: 0.9098 - val_recall_1: 0.9098\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2e8820fc10>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFKemL1-N0-_"
      },
      "source": [
        "Evaluate and print Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bn8itdlN0-_"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    ''' Function to calculate f1 score '''\n",
        "    \n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voFsUDB5N0-_",
        "outputId": "89fdfa79-a2e7-4398-ee57-c23c3a1e1ae1"
      },
      "source": [
        "# Evaluate model on the test set\n",
        "loss, accuracy, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
        "# Print metrics\n",
        "print('')\n",
        "print('Accuracy  : {:.4f}'.format(accuracy))\n",
        "print('Precision : {:.4f}'.format(precision))\n",
        "print('Recall    : {:.4f}'.format(recall))\n",
        "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy  : 0.9098\n",
            "Precision : 0.9098\n",
            "Recall    : 0.9098\n",
            "F1 Score  : 0.9098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl7DDjqWN0-_"
      },
      "source": [
        "Get Encode of Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JckxuL8eN0-_"
      },
      "source": [
        "def get_encode(x):\n",
        "  x = token.texts_to_sequences(x)\n",
        "  x = pad_sequences(x,maxlen = max_kata, padding = \"post\")\n",
        "  return x"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26saoZ8PN0-_"
      },
      "source": [
        "Get Sentiment Classesof Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlHpbGVBN0_A"
      },
      "source": [
        "def get_sentiment_classes(x):\n",
        "  x = get_encode(x)\n",
        "  predict_x=model.predict(x) \n",
        "  classes_x=np.argmax(predict_x,axis=1)\n",
        "  sentiment_classes = ['tidak kasar','kasar']\n",
        "  print('kata tersebut mengandung konotasi',sentiment_classes[classes_x[0]])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhUq1or9N0_A"
      },
      "source": [
        "Predict Data 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ijoqxHN0_B",
        "outputId": "9c9d89a1-0968-4f08-c058-398be677a2db"
      },
      "source": [
        "# untuk melakukan prediksi kata yang tidak kasar \n",
        "get_sentiment_classes(['ibu peri hari ini cantik banget ya'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi tidak kasar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2FoND1KN0_B"
      },
      "source": [
        "Predict Data 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbSfoQmFN0_B",
        "outputId": "eeee7a32-12f3-44c3-97e6-4ca353809fb3"
      },
      "source": [
        "# untuk melakukan prediksi kata yang kasar\n",
        "get_sentiment_classes(['bangsat cok raimu koyok asu'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi kasar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WNkqlXoNt73"
      },
      "source": [
        "# **60 40 ratio**\n",
        "Performing learning for 60% data training and 40% data testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h6rs63aN1wk"
      },
      "source": [
        "Split data test and test test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL7X2xg2N1wl"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1, test_size = 0.4, stratify=y)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.4, random_state=1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd3_tt5GN1wl"
      },
      "source": [
        "Change to Data to Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3oC2n1sN1wm"
      },
      "source": [
        "x_train = np.asarray(x_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIPnlWQrN1wm"
      },
      "source": [
        "Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo5n0zglN1wm",
        "outputId": "94f2d1d4-76c2-46e9-9746-6c1215ad24ab"
      },
      "source": [
        "vec_size = 100\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(vocab,vec_size,input_length=max_kata))\n",
        "model.add(Conv1D(64,3,activation='relu'))\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 100)          1326800   \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 98, 64)            19264     \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,346,194\n",
            "Trainable params: 1,346,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpqWpplaN1wm"
      },
      "source": [
        "from keras.metrics import Precision, Recall\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy', Precision(), Recall()])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_etqRW0YN1wn",
        "outputId": "2108a6b3-ff02-491b-914d-531e094c95fc"
      },
      "source": [
        "model.fit(x_train,y_train, epochs=10, validation_data =(x_test,y_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "148/148 [==============================] - 7s 41ms/step - loss: 0.5592 - accuracy: 0.7025 - precision_2: 0.7025 - recall_2: 0.7025 - val_loss: 0.3631 - val_accuracy: 0.8617 - val_precision_2: 0.8617 - val_recall_2: 0.8617\n",
            "Epoch 2/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.2312 - accuracy: 0.9176 - precision_2: 0.9176 - recall_2: 0.9176 - val_loss: 0.2318 - val_accuracy: 0.9126 - val_precision_2: 0.9126 - val_recall_2: 0.9126\n",
            "Epoch 3/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.1150 - accuracy: 0.9613 - precision_2: 0.9613 - recall_2: 0.9613 - val_loss: 0.2498 - val_accuracy: 0.9118 - val_precision_2: 0.9118 - val_recall_2: 0.9118\n",
            "Epoch 4/10\n",
            "148/148 [==============================] - 6s 38ms/step - loss: 0.0684 - accuracy: 0.9812 - precision_2: 0.9812 - recall_2: 0.9812 - val_loss: 0.2756 - val_accuracy: 0.9091 - val_precision_2: 0.9091 - val_recall_2: 0.9091\n",
            "Epoch 5/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.0440 - accuracy: 0.9871 - precision_2: 0.9871 - recall_2: 0.9871 - val_loss: 0.3100 - val_accuracy: 0.9087 - val_precision_2: 0.9087 - val_recall_2: 0.9087\n",
            "Epoch 6/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.0297 - accuracy: 0.9915 - precision_2: 0.9915 - recall_2: 0.9915 - val_loss: 0.3467 - val_accuracy: 0.9036 - val_precision_2: 0.9036 - val_recall_2: 0.9036\n",
            "Epoch 7/10\n",
            "148/148 [==============================] - 6s 38ms/step - loss: 0.0262 - accuracy: 0.9930 - precision_2: 0.9930 - recall_2: 0.9930 - val_loss: 0.3756 - val_accuracy: 0.8967 - val_precision_2: 0.8967 - val_recall_2: 0.8967\n",
            "Epoch 8/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.0174 - accuracy: 0.9951 - precision_2: 0.9951 - recall_2: 0.9951 - val_loss: 0.4033 - val_accuracy: 0.9011 - val_precision_2: 0.9011 - val_recall_2: 0.9011\n",
            "Epoch 9/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.0141 - accuracy: 0.9968 - precision_2: 0.9968 - recall_2: 0.9968 - val_loss: 0.4243 - val_accuracy: 0.8985 - val_precision_2: 0.8985 - val_recall_2: 0.8985\n",
            "Epoch 10/10\n",
            "148/148 [==============================] - 5s 34ms/step - loss: 0.0095 - accuracy: 0.9975 - precision_2: 0.9975 - recall_2: 0.9975 - val_loss: 0.4450 - val_accuracy: 0.8988 - val_precision_2: 0.8988 - val_recall_2: 0.8988\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2e87e86710>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BtC46R4N1wn"
      },
      "source": [
        "Evaluate and print Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTxhu7lvN1wn"
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    ''' Function to calculate f1 score '''\n",
        "    \n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NqD45eGN1wn",
        "outputId": "40b9c01d-25d9-4914-9b76-c32701c62076"
      },
      "source": [
        "# Evaluate model on the test set\n",
        "loss, accuracy, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
        "# Print metrics\n",
        "print('')\n",
        "print('Accuracy  : {:.4f}'.format(accuracy))\n",
        "print('Precision : {:.4f}'.format(precision))\n",
        "print('Recall    : {:.4f}'.format(recall))\n",
        "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy  : 0.8988\n",
            "Precision : 0.8988\n",
            "Recall    : 0.8988\n",
            "F1 Score  : 0.8988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY9aQqdbN1wn"
      },
      "source": [
        "Get Encode of Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og9fHX93N1wn"
      },
      "source": [
        "def get_encode(x):\n",
        "  x = token.texts_to_sequences(x)\n",
        "  x = pad_sequences(x,maxlen = max_kata, padding = \"post\")\n",
        "  return x"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9vP0ZZ5N1wn"
      },
      "source": [
        "Get Sentiment Classesof Predict Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Acu-j3UN1wo"
      },
      "source": [
        "def get_sentiment_classes(x):\n",
        "  x = get_encode(x)\n",
        "  predict_x=model.predict(x) \n",
        "  classes_x=np.argmax(predict_x,axis=1)\n",
        "  sentiment_classes = ['tidak kasar','kasar']\n",
        "  print('kata tersebut mengandung konotasi',sentiment_classes[classes_x[0]])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeEXAC0-N1wo"
      },
      "source": [
        "Predict Data 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB3eV_00N1wo",
        "outputId": "02ec0a11-6e97-4ee4-85bf-cd1d59873b22"
      },
      "source": [
        "# untuk melakukan prediksi kata yang tidak kasar \n",
        "get_sentiment_classes(['ibu peri hari ini cantik banget ya'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi kasar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6uwMPtQN1wo"
      },
      "source": [
        "Predict Data 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v84OY99eN1wo",
        "outputId": "de364455-f1bc-4e92-8e26-ecf3277130aa"
      },
      "source": [
        "# untuk melakukan prediksi kata yang kasar\n",
        "get_sentiment_classes(['bangsat cok raimu koyok asu'])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kata tersebut mengandung konotasi kasar\n"
          ]
        }
      ]
    }
  ]
}