{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHXkYCI0ludT"
   },
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "E3XOqlVnQGS_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Embedding, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50D8gTIilxCw"
   },
   "source": [
    "Read CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "dYAXPjadlI3i",
    "outputId": "2293b591-03f1-41a3-d849-d1add1160aaf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abusive</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cowok usaha lacak perhati gue lantas remeh per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>telat tau edan sarap gue gaul cigax jifla cal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>41 kadang pikir percaya tuhan jatuh kali kali ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ku tau mata sipit lihat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kaum cebong kafir lihat dongok dungu haha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Abusive                                              Tweet\n",
       "0        1  cowok usaha lacak perhati gue lantas remeh per...\n",
       "1        1  telat tau edan sarap gue gaul cigax jifla cal ...\n",
       "2        0  41 kadang pikir percaya tuhan jatuh kali kali ...\n",
       "3        0                            ku tau mata sipit lihat\n",
       "4        1          kaum cebong kafir lihat dongok dungu haha"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuwC3k6mly3r"
   },
   "source": [
    "Drop Missing Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "amCq7-1UlNTX"
   },
   "outputs": [],
   "source": [
    "# drop missing rows\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bD1Pp85l0i_"
   },
   "source": [
    "Print Lenght of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wm12Datjlfri",
    "outputId": "ce433226-c5e8-412a-8302-34903276ac4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13121\n"
     ]
    }
   ],
   "source": [
    "text = df[\"Tweet\"].tolist()\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcnanCkLuF6c"
   },
   "source": [
    "Make it to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ucRFc5iJuFH1",
    "outputId": "27c409ed-d6de-4044-a651-5b791a863449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y = df[\"Abusive\"]\n",
    "y = to_categorical(y)\n",
    "print(y)\n",
    "#0 itu negatif, 1 itu positif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6AfkUo4mHE0"
   },
   "source": [
    "Count Data Each Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVrhJbf_mEtE",
    "outputId": "451506d8-b38a-4e2f-ba39-560596d2ea17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8088\n",
       "1    5033\n",
       "Name: Abusive, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Abusive\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xH0x1jptm7nh"
   },
   "source": [
    "Do Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GXRKRirwm-li"
   },
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Od7zmpVOnBD1"
   },
   "outputs": [],
   "source": [
    "# if you want to print every index word\n",
    "# token.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjZAT2innQOl",
    "outputId": "785fa52e-a2b3-43b8-83cc-7bf8965521cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13268\n"
     ]
    }
   ],
   "source": [
    "vocab = len(token.index_word)+1\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSYPIUiPn1YD"
   },
   "source": [
    "Test Text to Tokenize Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRB_WEIWnULT",
    "outputId": "d1e68ff6-3350-407a-db10-f95d690c973c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[558, 1035, 8]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['sinting kau ya']\n",
    "token.texts_to_sequences(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEmrQUYln9Mv"
   },
   "source": [
    "Encode Every Each Tweet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bm3AM6wLoBt_"
   },
   "outputs": [],
   "source": [
    "encode_text = token.texts_to_sequences(text)\n",
    "# if you want to print every tokenizer tweet\n",
    "# print(encode_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkoEI0mEoOzf"
   },
   "source": [
    "Do Padding Every Encode Tweet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFaDbqgfoVn8",
    "outputId": "2f27e35c-6dee-4fe4-ca2d-8585b78592ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 324  161 3546 ...    0    0    0]\n",
      " [1908   49  464 ...    0    0    0]\n",
      " [3547  598  101 ...    0    0    0]\n",
      " ...\n",
      " [  66   66  376 ...    0    0    0]\n",
      " [ 111 2819  291 ...    0    0    0]\n",
      " [ 569  325    8 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "max_kata = 100\n",
    "x=pad_sequences(encode_text,maxlen = max_kata, padding=\"post\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-SCJ53wNN2V"
   },
   "source": [
    "# **80 20 ratio**\n",
    "Performing learning for 80% data training and 20% data testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCz4v-Rbthge"
   },
   "source": [
    "Split data test and test test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ezm4E--wtlw-"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1, test_size = 0.2, stratify=y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFct96Y7tnCl"
   },
   "source": [
    "Change to Data to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaQDZkMqtq7Z"
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_SSH7z2t20F"
   },
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xo1q2gRxt4hD",
    "outputId": "b582c5e8-fc07-4b69-fa53-5a7b5781b6ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          3980400   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 93, 64)            153664    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 46, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 46, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 46, 32)            2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 46, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 46, 16)            528       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 4,136,706\n",
      "Trainable params: 4,136,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "vec_size=300\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(vocab,vec_size,input_length=max_kata))\n",
    "model.add(Conv1D(64,8,activation=\"relu\"))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g733dI0ivLWK"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Kd8SXbDvMov",
    "outputId": "ec2e004e-94e2-43bf-b44f-6761ec4b17ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "263/263 [==============================] - 45s 155ms/step - loss: 0.6053 - accuracy: 0.6608 - precision: 0.6608 - recall: 0.6608 - val_loss: 0.3329 - val_accuracy: 0.8670 - val_precision: 0.8670 - val_recall: 0.8670\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 39s 147ms/step - loss: 0.2647 - accuracy: 0.9002 - precision: 0.9002 - recall: 0.9002 - val_loss: 0.2376 - val_accuracy: 0.9109 - val_precision: 0.9109 - val_recall: 0.9109\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 40s 153ms/step - loss: 0.1466 - accuracy: 0.9543 - precision: 0.9543 - recall: 0.9543 - val_loss: 0.2350 - val_accuracy: 0.9116 - val_precision: 0.9116 - val_recall: 0.9116\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 39s 147ms/step - loss: 0.0878 - accuracy: 0.9725 - precision: 0.9725 - recall: 0.9725 - val_loss: 0.2718 - val_accuracy: 0.9109 - val_precision: 0.9109 - val_recall: 0.9109\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 38s 145ms/step - loss: 0.0645 - accuracy: 0.9786 - precision: 0.9786 - recall: 0.9786 - val_loss: 0.3041 - val_accuracy: 0.9063 - val_precision: 0.9063 - val_recall: 0.9063\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 0.0471 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850 - val_loss: 0.3478 - val_accuracy: 0.9021 - val_precision: 0.9021 - val_recall: 0.9021\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 38s 146ms/step - loss: 0.0427 - accuracy: 0.9861 - precision: 0.9861 - recall: 0.9861 - val_loss: 0.3857 - val_accuracy: 0.9006 - val_precision: 0.9006 - val_recall: 0.9006\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 39s 147ms/step - loss: 0.0326 - accuracy: 0.9896 - precision: 0.9896 - recall: 0.9896 - val_loss: 0.4037 - val_accuracy: 0.9040 - val_precision: 0.9040 - val_recall: 0.9040\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 39s 147ms/step - loss: 0.0361 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - val_loss: 0.4387 - val_accuracy: 0.8949 - val_precision: 0.8949 - val_recall: 0.8949\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 39s 147ms/step - loss: 0.0290 - accuracy: 0.9912 - precision: 0.9912 - recall: 0.9912 - val_loss: 0.4798 - val_accuracy: 0.8971 - val_precision: 0.8971 - val_recall: 0.8971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9fb8b34dd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=10, validation_data =(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g81gHnxjvRGa"
   },
   "source": [
    "Evaluate and print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diiCq6bembt4"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    ''' Function to calculate f1 score '''\n",
    "    \n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qL1-nLk9dHcE",
    "outputId": "f0012634-1bb9-4f1e-9034-1643a5ebfc23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy  : 0.8971\n",
      "Precision : 0.8971\n",
      "Recall    : 0.8971\n",
      "F1 Score  : 0.8971\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on the test set\n",
    "loss, accuracy, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
    "# Print metrics\n",
    "print('')\n",
    "print('Accuracy  : {:.4f}'.format(accuracy))\n",
    "print('Precision : {:.4f}'.format(precision))\n",
    "print('Recall    : {:.4f}'.format(recall))\n",
    "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDCHxeXIzjgl"
   },
   "source": [
    "Get Encode of Predict Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_uQQnmUzmiT"
   },
   "outputs": [],
   "source": [
    "def get_encode(x):\n",
    "  x = token.texts_to_sequences(x)\n",
    "  x = pad_sequences(x,maxlen = max_kata, padding = \"post\")\n",
    "  return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDVmlhWCzqMm"
   },
   "source": [
    "Get Sentiment Classesof Predict Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caFA2Sz3zulF"
   },
   "outputs": [],
   "source": [
    "def get_sentiment_classes(x):\n",
    "  x = get_encode(x)\n",
    "  predict_x=model.predict(x) \n",
    "  classes_x=np.argmax(predict_x,axis=1)\n",
    "  sentiment_classes = ['tidak kasar','kasar']\n",
    "  print('kata tersebut mengandung konotasi',sentiment_classes[classes_x[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKEGdVfezveT"
   },
   "source": [
    "Predict Data 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvFAB00Qzy0E",
    "outputId": "004c31d9-6149-4838-b89f-d985c859a794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kata tersebut mengandung konotasi tidak kasar\n"
     ]
    }
   ],
   "source": [
    "# untuk melakukan prediksi kata yang tidak kasar \n",
    "get_sentiment_classes(['ibu peri hari ini cantik banget ya'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PbAQ7q4zz9v"
   },
   "source": [
    "Predict Data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVCaPYuFz1fq",
    "outputId": "0e58727e-30e9-44c0-e7ce-b90b13adf194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kata tersebut mengandung konotasi kasar\n"
     ]
    }
   ],
   "source": [
    "# untuk melakukan prediksi kata yang kasar\n",
    "get_sentiment_classes(['woi babi lo anjing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TC-cd_2RNVTt"
   },
   "source": [
    "# **70 30 ratio**\n",
    "Performing learning for 70% data training and 30% data testing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYXIyDBoN0-9"
   },
   "source": [
    "Split data test and test test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0w7OAVK1N0--"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1, test_size = 0.3, stratify=y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HGV7x5ZN0--"
   },
   "source": [
    "Change to Data to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5KfaP0MN0--"
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vO8i8fr4N0--"
   },
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDV1S_lrN0--",
    "outputId": "534868bd-4384-407e-9832-64e166f3fd5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          3980400   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 93, 64)            153664    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 46, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 46, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 46, 32)            2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 46, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 46, 16)            528       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 4,136,706\n",
      "Trainable params: 4,136,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "vec_size=300\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(vocab,vec_size,input_length=max_kata))\n",
    "model.add(Conv1D(64,8,activation=\"relu\"))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsY4HNNpN0--"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eRCvkUBN0-_",
    "outputId": "24003dfc-687e-4ed4-b31a-7eb3d8a13dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "201/201 [==============================] - 32s 155ms/step - loss: 0.6473 - accuracy: 0.6353 - precision_1: 0.6353 - recall_1: 0.6353 - val_loss: 0.5037 - val_accuracy: 0.7836 - val_precision_1: 0.7836 - val_recall_1: 0.7836\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 30s 151ms/step - loss: 0.3357 - accuracy: 0.8671 - precision_1: 0.8671 - recall_1: 0.8671 - val_loss: 0.2571 - val_accuracy: 0.9088 - val_precision_1: 0.9088 - val_recall_1: 0.9088\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 31s 152ms/step - loss: 0.1561 - accuracy: 0.9516 - precision_1: 0.9516 - recall_1: 0.9516 - val_loss: 0.2529 - val_accuracy: 0.9065 - val_precision_1: 0.9065 - val_recall_1: 0.9065\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 30s 149ms/step - loss: 0.0886 - accuracy: 0.9736 - precision_1: 0.9736 - recall_1: 0.9736 - val_loss: 0.2911 - val_accuracy: 0.9030 - val_precision_1: 0.9030 - val_recall_1: 0.9030\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 31s 155ms/step - loss: 0.0555 - accuracy: 0.9827 - precision_1: 0.9827 - recall_1: 0.9827 - val_loss: 0.3354 - val_accuracy: 0.9053 - val_precision_1: 0.9053 - val_recall_1: 0.9053\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 32s 160ms/step - loss: 0.0447 - accuracy: 0.9852 - precision_1: 0.9852 - recall_1: 0.9852 - val_loss: 0.3815 - val_accuracy: 0.9012 - val_precision_1: 0.9012 - val_recall_1: 0.9012\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 32s 160ms/step - loss: 0.0421 - accuracy: 0.9885 - precision_1: 0.9885 - recall_1: 0.9885 - val_loss: 0.4197 - val_accuracy: 0.8954 - val_precision_1: 0.8954 - val_recall_1: 0.8954\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 33s 163ms/step - loss: 0.0299 - accuracy: 0.9913 - precision_1: 0.9913 - recall_1: 0.9913 - val_loss: 0.4685 - val_accuracy: 0.8951 - val_precision_1: 0.8951 - val_recall_1: 0.8951\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 33s 164ms/step - loss: 0.0265 - accuracy: 0.9916 - precision_1: 0.9916 - recall_1: 0.9916 - val_loss: 0.4809 - val_accuracy: 0.8969 - val_precision_1: 0.8969 - val_recall_1: 0.8969\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 33s 165ms/step - loss: 0.0159 - accuracy: 0.9952 - precision_1: 0.9952 - recall_1: 0.9952 - val_loss: 0.5439 - val_accuracy: 0.8984 - val_precision_1: 0.8984 - val_recall_1: 0.8984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9fb89519d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=10, validation_data =(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFKemL1-N0-_"
   },
   "source": [
    "Evaluate and print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Bn8itdlN0-_"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    ''' Function to calculate f1 score '''\n",
    "    \n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voFsUDB5N0-_",
    "outputId": "cfc6aa88-6854-4336-b3aa-527f5fda2004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy  : 0.8984\n",
      "Precision : 0.8984\n",
      "Recall    : 0.8984\n",
      "F1 Score  : 0.8984\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on the test set\n",
    "loss, accuracy, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
    "# Print metrics\n",
    "print('')\n",
    "print('Accuracy  : {:.4f}'.format(accuracy))\n",
    "print('Precision : {:.4f}'.format(precision))\n",
    "print('Recall    : {:.4f}'.format(recall))\n",
    "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl7DDjqWN0-_"
   },
   "source": [
    "Get Encode of Predict Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JckxuL8eN0-_"
   },
   "outputs": [],
   "source": [
    "def get_encode(x):\n",
    "  x = token.texts_to_sequences(x)\n",
    "  x = pad_sequences(x,maxlen = max_kata, padding = \"post\")\n",
    "  return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26saoZ8PN0-_"
   },
   "source": [
    "Get Sentiment Classesof Predict Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlHpbGVBN0_A"
   },
   "outputs": [],
   "source": [
    "def get_sentiment_classes(x):\n",
    "  x = get_encode(x)\n",
    "  predict_x=model.predict(x) \n",
    "  classes_x=np.argmax(predict_x,axis=1)\n",
    "  sentiment_classes = ['tidak kasar','kasar']\n",
    "  print('kata tersebut mengandung konotasi',sentiment_classes[classes_x[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhUq1or9N0_A"
   },
   "source": [
    "Predict Data 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9ijoqxHN0_B",
    "outputId": "a7bfc895-9fbc-445f-c31e-aba03e064d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kata tersebut mengandung konotasi tidak kasar\n"
     ]
    }
   ],
   "source": [
    "# untuk melakukan prediksi kata yang tidak kasar \n",
    "get_sentiment_classes(['ibu peri hari ini cantik banget ya'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2FoND1KN0_B"
   },
   "source": [
    "Predict Data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbSfoQmFN0_B",
    "outputId": "02232009-dcd4-4bf8-cb63-1932e6fa16a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kata tersebut mengandung konotasi kasar\n"
     ]
    }
   ],
   "source": [
    "# untuk melakukan prediksi kata yang kasar\n",
    "get_sentiment_classes(['woi babi lo anjing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYtYlBXlNkoe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WNkqlXoNt73"
   },
   "source": [
    "# **60 40 ratio**\n",
    "Performing learning for 60% data training and 40% data testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4h6rs63aN1wk"
   },
   "source": [
    "Split data test and test test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QL7X2xg2N1wl"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1, test_size = 0.4, stratify=y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kd3_tt5GN1wl"
   },
   "source": [
    "Change to Data to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3oC2n1sN1wm"
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIPnlWQrN1wm"
   },
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qo5n0zglN1wm",
    "outputId": "92fe2226-eeb6-421e-a1e5-5352741fd74d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 300)          3980400   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 93, 64)            153664    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 46, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 46, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 46, 32)            2080      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 46, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 46, 16)            528       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 4,136,706\n",
      "Trainable params: 4,136,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "vec_size=300\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(vocab,vec_size,input_length=max_kata))\n",
    "model.add(Conv1D(64,8,activation=\"relu\"))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OpqWpplaN1wm"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_etqRW0YN1wn",
    "outputId": "3a0be70e-4311-438c-f291-7d46d043267d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "148/148 [==============================] - 29s 185ms/step - loss: 0.6671 - accuracy: 0.6257 - precision_2: 0.6257 - recall_2: 0.6257 - val_loss: 0.6694 - val_accuracy: 0.6462 - val_precision_2: 0.6462 - val_recall_2: 0.6462\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 26s 179ms/step - loss: 0.5024 - accuracy: 0.7582 - precision_2: 0.7582 - recall_2: 0.7582 - val_loss: 0.3796 - val_accuracy: 0.8645 - val_precision_2: 0.8645 - val_recall_2: 0.8645\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 27s 179ms/step - loss: 0.2115 - accuracy: 0.9289 - precision_2: 0.9289 - recall_2: 0.9289 - val_loss: 0.2909 - val_accuracy: 0.8988 - val_precision_2: 0.8988 - val_recall_2: 0.8988\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 28s 186ms/step - loss: 0.1147 - accuracy: 0.9670 - precision_2: 0.9670 - recall_2: 0.9670 - val_loss: 0.2942 - val_accuracy: 0.8946 - val_precision_2: 0.8946 - val_recall_2: 0.8946\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 27s 185ms/step - loss: 0.0748 - accuracy: 0.9778 - precision_2: 0.9778 - recall_2: 0.9778 - val_loss: 0.3042 - val_accuracy: 0.8998 - val_precision_2: 0.8998 - val_recall_2: 0.8998\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 27s 185ms/step - loss: 0.0510 - accuracy: 0.9831 - precision_2: 0.9831 - recall_2: 0.9831 - val_loss: 0.3332 - val_accuracy: 0.8990 - val_precision_2: 0.8990 - val_recall_2: 0.8990\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 27s 185ms/step - loss: 0.0468 - accuracy: 0.9869 - precision_2: 0.9869 - recall_2: 0.9869 - val_loss: 0.4234 - val_accuracy: 0.8905 - val_precision_2: 0.8905 - val_recall_2: 0.8905\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 27s 183ms/step - loss: 0.0298 - accuracy: 0.9924 - precision_2: 0.9924 - recall_2: 0.9924 - val_loss: 0.4226 - val_accuracy: 0.8916 - val_precision_2: 0.8916 - val_recall_2: 0.8916\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 27s 184ms/step - loss: 0.0195 - accuracy: 0.9953 - precision_2: 0.9953 - recall_2: 0.9953 - val_loss: 0.5077 - val_accuracy: 0.8853 - val_precision_2: 0.8853 - val_recall_2: 0.8853\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 27s 184ms/step - loss: 0.0202 - accuracy: 0.9941 - precision_2: 0.9941 - recall_2: 0.9941 - val_loss: 0.4856 - val_accuracy: 0.8964 - val_precision_2: 0.8964 - val_recall_2: 0.8964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9fb8497c50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=10, validation_data =(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BtC46R4N1wn"
   },
   "source": [
    "Evaluate and print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTxhu7lvN1wn"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    ''' Function to calculate f1 score '''\n",
    "    \n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NqD45eGN1wn",
    "outputId": "c006ff14-2929-4d3a-ce70-4a0f154e841e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy  : 0.8964\n",
      "Precision : 0.8964\n",
      "Recall    : 0.8964\n",
      "F1 Score  : 0.8964\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on the test set\n",
    "loss, accuracy, precision, recall = model.evaluate(x_test, y_test, verbose=0)\n",
    "# Print metrics\n",
    "print('')\n",
    "print('Accuracy  : {:.4f}'.format(accuracy))\n",
    "print('Precision : {:.4f}'.format(precision))\n",
    "print('Recall    : {:.4f}'.format(recall))\n",
    "print('F1 Score  : {:.4f}'.format(f1_score(precision, recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY9aQqdbN1wn"
   },
   "source": [
    "Get Encode of Predict Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "og9fHX93N1wn"
   },
   "outputs": [],
   "source": [
    "def get_encode(x):\n",
    "  x = token.texts_to_sequences(x)\n",
    "  x = pad_sequences(x,maxlen = max_kata, padding = \"post\")\n",
    "  return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9vP0ZZ5N1wn"
   },
   "source": [
    "Get Sentiment Classesof Predict Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Acu-j3UN1wo"
   },
   "outputs": [],
   "source": [
    "def get_sentiment_classes(x):\n",
    "  x = get_encode(x)\n",
    "  predict_x=model.predict(x) \n",
    "  classes_x=np.argmax(predict_x,axis=1)\n",
    "  sentiment_classes = ['tidak kasar','kasar']\n",
    "  print('kata tersebut mengandung konotasi',sentiment_classes[classes_x[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeEXAC0-N1wo"
   },
   "source": [
    "Predict Data 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kB3eV_00N1wo",
    "outputId": "c3ecd46d-c609-42c5-b22e-d7482c4b3cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kata tersebut mengandung konotasi tidak kasar\n"
     ]
    }
   ],
   "source": [
    "# untuk melakukan prediksi kata yang tidak kasar \n",
    "get_sentiment_classes(['ibu peri hari ini cantik banget ya'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6uwMPtQN1wo"
   },
   "source": [
    "Predict Data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v84OY99eN1wo",
    "outputId": "fc1a1cc4-dff1-485e-fc4f-72bcc2386172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kata tersebut mengandung konotasi kasar\n"
     ]
    }
   ],
   "source": [
    "# untuk melakukan prediksi kata yang kasar\n",
    "get_sentiment_classes(['woi babi lo anjing'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "file sampah.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
